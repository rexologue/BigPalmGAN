{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model_utils import setup_generator, setup_discriminator\n",
    "\n",
    "G = setup_generator(4, -1)\n",
    "D = setup_discriminator(4)\n",
    "\n",
    "G.load_state_dict(torch.load(r'E:\\Data\\biggan\\g.pth', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from support_utils import get_latent_input\n",
    "\n",
    "################################################################\n",
    "# //////////////////////////////////////////////////////////// #\n",
    "################################################################\n",
    "def compute_gradient_penalty(discriminator, real_images, fake_images, labels, device):\n",
    "    alpha = torch.rand(real_images.size(0), 1, 1, 1, device=device)\n",
    "    \n",
    "    interpolates = (alpha * real_images + (1 - alpha) * fake_images).requires_grad_(True)\n",
    "    \n",
    "    d_interpolates = discriminator(interpolates, labels)\n",
    "    \n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=torch.ones_like(d_interpolates, device=device),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True\n",
    "    )[0]\n",
    "    \n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    \n",
    "    return gradient_penalty\n",
    "\n",
    "################################################################\n",
    "# //////////////////////////////////////////////////////////// #\n",
    "################################################################\n",
    "def train_discriminator(generator,\n",
    "                        discriminator,\n",
    "                        real_images,\n",
    "                        labels,\n",
    "                        d_loss_fn,\n",
    "                        optimizer_D,\n",
    "                        lambda_gp,\n",
    "                        device,\n",
    "                        scaler):\n",
    "    \n",
    "    # Generate fake images\n",
    "    noise, labels = get_latent_input(real_images.size(0), labels, device)\n",
    "    \n",
    "    with torch.amp.autocast(device_type=device, dtype=torch.float16):\n",
    "        fake_images = generator(noise, labels)\n",
    "\n",
    "        # Get discriminator outputs\n",
    "        real_outputs = discriminator(real_images, labels)\n",
    "        fake_outputs = discriminator(fake_images.detach(), labels)\n",
    "\n",
    "        # Discriminator losses\n",
    "        d_adv_loss = d_loss_fn(real_outputs, fake_outputs)\n",
    "        \n",
    "    # Compute gradient penalty in full precision\n",
    "    with torch.amp.autocast(device_type='cuda', enabled=False):\n",
    "        gradient_penalty = compute_gradient_penalty(discriminator, real_images, fake_images.detach(), labels, device)\n",
    "        \n",
    "    d_loss = d_adv_loss + lambda_gp * gradient_penalty\n",
    "\n",
    "    # Backpropagation and optimization\n",
    "    optimizer_D.zero_grad()\n",
    "    scaler.scale(d_loss).backward()\n",
    "    scaler.step(optimizer_D)\n",
    "    scaler.update()\n",
    "\n",
    "    # Compute accuracies\n",
    "    real_acc = (real_outputs > 0).float().mean()\n",
    "    fake_acc = (fake_outputs < 0).float().mean()\n",
    "\n",
    "    return d_loss.item(), real_acc.item(), fake_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "class PalmDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Dataset class for palm images with labels.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "                         transforms.RandomHorizontalFlip(),\n",
    "                         transforms.RandomVerticalFlip(),\n",
    "                         transforms.RandomRotation(15),\n",
    "                         transforms.RandomResizedCrop(512, scale=(0.8, 1.0)),\n",
    "                         transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "                         transforms.ToTensor(),\n",
    "                         transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "                         ])\n",
    "        \n",
    "        self.image_paths = os.listdir(root_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name = self.image_paths[idx]\n",
    "        img_path = os.path.join(self.root_dir, name)\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            image = Image.new(\"RGB\", (512, 512))\n",
    "            \n",
    "        label = 0\n",
    "        \n",
    "        if name.startswith('lr'):\n",
    "            label = 1\n",
    "        if name.startswith('rw'):\n",
    "            label = 2\n",
    "        if name.startswith('rb'):\n",
    "            label = 3\n",
    "        \n",
    "        image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "    \n",
    "loader = torch.utils.data.DataLoader(dataset=PalmDataset(r'E:\\Data\\Biometric\\Set\\Palms11kSplit\\test'), batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from support_utils import save_sample_images_by_class\n",
    "\n",
    "for batch, labels in loader:\n",
    "    \n",
    "    batch.cuda()\n",
    "    \n",
    "    data = {\n",
    "        0: batch[0],\n",
    "        1: batch[1],\n",
    "        2: batch[2],\n",
    "        3: batch[3]\n",
    "    }\n",
    "    \n",
    "    save_sample_images_by_class(data, 3, r'', 4)\n",
    "    \n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
